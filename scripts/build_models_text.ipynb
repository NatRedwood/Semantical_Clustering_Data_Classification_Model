{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import importlib, import_ipynb\n",
    "import data_clean_order_text as data\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import experimental\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model building imports\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "from keras.layers import Conv1D, SimpleRNN, Bidirectional, MaxPooling1D, GlobalMaxPool1D, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# matplotlib defaults\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading ordered data from data_clean_order_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ordered_super_alpha_text\n",
    "%store -r ordered_class_alpha_text\n",
    "%store -r ordered_sem_clusters_desc_text\n",
    "%store -r ordered_sem_clusters_asc_text\n",
    "%store -r ordered_sem_clusters_shuffled_per_superclass_text\n",
    "%store -r test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental data orderings on headlines TRAIN EXAMPLES\n",
    "X1_train = ordered_super_alpha_text['cleaned_headline']\n",
    "X2_train = ordered_class_alpha_text['cleaned_headline']\n",
    "X3_train = ordered_sem_clusters_desc_text['cleaned_headline']\n",
    "X4_train = ordered_sem_clusters_asc_text['cleaned_headline']\n",
    "X5_train = ordered_sem_clusters_shuffled_per_superclass_text['cleaned_headline']\n",
    "\n",
    "# Experimental data orderings on short_description #TODO\n",
    "\n",
    "# TRAIN LABELS\n",
    "Y1_train = ordered_super_alpha_text['class']\n",
    "Y2_train = ordered_class_alpha_text['class']\n",
    "Y3_train = ordered_sem_clusters_desc_text['class']\n",
    "Y4_train = ordered_sem_clusters_asc_text['class']\n",
    "Y5_train = ordered_sem_clusters_shuffled_per_superclass_text['class']\n",
    "\n",
    "# TEST EXAMPLES\n",
    "X_test = test_df['cleaned_headline']\n",
    "Y_test = test_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      QUEER VOICES\n",
       "1             WOMEN\n",
       "2      BLACK VOICES\n",
       "3     LATINO VOICES\n",
       "4      QUEER VOICES\n",
       "          ...      \n",
       "95     QUEER VOICES\n",
       "96     QUEER VOICES\n",
       "97     QUEER VOICES\n",
       "98     QUEER VOICES\n",
       "99     BLACK VOICES\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ARTS\n",
       "1     ARTS\n",
       "2     ARTS\n",
       "3     ARTS\n",
       "4     ARTS\n",
       "      ... \n",
       "95    ARTS\n",
       "96    ARTS\n",
       "97    ARTS\n",
       "98    ARTS\n",
       "99    ARTS\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44360     GENERAL POLITICS\n",
       "51103     GENERAL POLITICS\n",
       "21539     GENERAL POLITICS\n",
       "49127     GENERAL POLITICS\n",
       "32623     GENERAL POLITICS\n",
       "                ...       \n",
       "1901      GENERAL POLITICS\n",
       "11229     GENERAL POLITICS\n",
       "49088     GENERAL POLITICS\n",
       "35907     GENERAL POLITICS\n",
       "117407    GENERAL POLITICS\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182268    CULTURE & ARTS\n",
       "140009    CULTURE & ARTS\n",
       "181708    CULTURE & ARTS\n",
       "196465    CULTURE & ARTS\n",
       "137307    CULTURE & ARTS\n",
       "               ...      \n",
       "669       CULTURE & ARTS\n",
       "146767    CULTURE & ARTS\n",
       "153814    CULTURE & ARTS\n",
       "182259    CULTURE & ARTS\n",
       "165747    CULTURE & ARTS\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y4_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14822    WORLD NEWS\n",
       "25771    WORLD NEWS\n",
       "5363     WORLD NEWS\n",
       "1254     WORLD NEWS\n",
       "8672     WORLD NEWS\n",
       "            ...    \n",
       "30909    WORLD NEWS\n",
       "26292    WORLD NEWS\n",
       "23705    WORLD NEWS\n",
       "30575    WORLD NEWS\n",
       "6264     WORLD NEWS\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y5_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102504    GENERAL POLITICS\n",
       "137099        FOOD & DRINK\n",
       "162103            WEDDINGS\n",
       "201412           PARENTING\n",
       "172974        BLACK VOICES\n",
       "                ...       \n",
       "148578         ENVIRONMENT\n",
       "86540                GREEN\n",
       "130890               MEDIA\n",
       "38289             RELIGION\n",
       "161439            WEDDINGS\n",
       "Name: class, Length: 100, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One-hot encoding and indexing of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input data:  (41905,)\n",
      "shape of target variable:  (41905,)\n",
      "Length of word index: 27359\n"
     ]
    }
   ],
   "source": [
    "# TEST DATA\n",
    "\n",
    "# one hot encoding using keras tokenizer and pad sequencing\n",
    "encoder = LabelEncoder()\n",
    "Y_test = encoder.fit_transform(Y_test)\n",
    "print(\"shape of input data: \", X_test.shape)\n",
    "print(\"shape of target variable: \", Y_test.shape)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000, oov_token='<00V>') \n",
    "tokenizer.fit_on_texts(X_test) # build the word index\n",
    "# padding X_test text input data\n",
    "test_seq = tokenizer.texts_to_sequences(X_test) # converts strinfs into integer lists\n",
    "test_padseq = pad_sequences(test_seq, maxlen=20) # pads the integer lists to 2D integer tensor \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "max_words = 150000  # total number of words to consider in embedding layer\n",
    "total_words = len(word_index)\n",
    "maxlen = 20 # max length of sequence \n",
    "Y_test = to_categorical(Y_test, num_classes=42)\n",
    "print(\"Length of word index:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT ORDER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input data:  (167616,)\n",
      "shape of target variable:  (167616,)\n",
      "Length of word index: 52548\n"
     ]
    }
   ],
   "source": [
    "# ORDER 1 TRAIN DATA\n",
    "X_train = X1_train\n",
    "Y_train = Y1_train\n",
    "\n",
    "# one hot encoding using keras tokenizer and pad sequencing\n",
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "print(\"shape of input data: \", X_train.shape)\n",
    "print(\"shape of target variable: \", Y_train.shape)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=100000, oov_token='<00V>') \n",
    "tokenizer.fit_on_texts(X_train) # build the word index\n",
    "# padding X_train text input data\n",
    "train_seq = tokenizer.texts_to_sequences(X_train) # converts strinfs into integer lists\n",
    "train_padseq = pad_sequences(train_seq, maxlen=20) # pads the integer lists to 2D integer tensor \n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "max_words = 150000  # total number of words to consider in embedding layer\n",
    "total_words = len(word_index)\n",
    "maxlen = 20 # max length of sequence \n",
    "Y_train = to_categorical(Y_train, num_classes=42)\n",
    "print(\"Length of word index:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training using embedding layer and RNN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 20, 70)            3678360   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 20, 128)          17280     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 20, 128)          24704     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " simple_rnn_14 (SimpleRNN)   (None, 32)                5152      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 42)                1386      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,726,882\n",
      "Trainable params: 3,726,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# basline model using embedding layers and simpleRNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 70, input_length=maxlen))\n",
    "model.add(Bidirectional(SimpleRNN(64, dropout=0.1, recurrent_dropout=0.20, activation='tanh', return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(64, dropout=0.1, recurrent_dropout=0.30, activation='tanh', return_sequences=True)))\n",
    "model.add(SimpleRNN(32, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(42, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "#SETUP A EARLY STOPPING CALL and model check point API\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='accuracy',\n",
    "                                             patience=5,\n",
    "                                              verbose=1,\n",
    "                                              mode='min'\n",
    "                                             )\n",
    "checkpointer = ModelCheckpoint(filepath='bestvalue',moniter='val_loss', verbose=0, save_best_only=True)\n",
    "callback_list = [checkpointer, earlystopping]\n",
    "callback_list = [earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 870, in step_function  **\n        write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 3051, in write_scalar_summaries\n        tf.summary.scalar('batch_' + name, value, step=step)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\scalar\\summary_v2.py\", line 84, in scalar\n        getattr(tf.summary.experimental, \"summary_scope\", None)\n\n    AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'experimental'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\natal\\CSCI5922_NN\\FinalProject\\Semantical_Clustering_Data_Classification_Model\\scripts\\build_models_text.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# fit model to the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_padseq, Y_train, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                    batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m ,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                    )\n",
      "File \u001b[1;32mc:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 870, in step_function  **\n        write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 3051, in write_scalar_summaries\n        tf.summary.scalar('batch_' + name, value, step=step)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\scalar\\summary_v2.py\", line 84, in scalar\n        getattr(tf.summary.experimental, \"summary_scope\", None)\n\n    AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'experimental'\n"
     ]
    }
   ],
   "source": [
    "# fit model to the data\n",
    "history = model.fit(train_padseq, Y_train, \n",
    "                   batch_size=128, \n",
    "                    epochs=15 ,\n",
    "                    validation_split=0.2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 870, in step_function  **\n        write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 3051, in write_scalar_summaries\n        tf.summary.scalar('batch_' + name, value, step=step)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\scalar\\summary_v2.py\", line 84, in scalar\n        getattr(tf.summary.experimental, \"summary_scope\", None)\n\n    AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'experimental'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\natal\\CSCI5922_NN\\FinalProject\\Semantical_Clustering_Data_Classification_Model\\scripts\\build_models_text.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# SETUP A EARLY STOPPING CALL and model check point API\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#earlystopping = keras.callbacks.EarlyStopping(monitor='accuracy',\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#                                         patience=5,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# fit model to the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_padseq, Y_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                    batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m ,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/natal/CSCI5922_NN/FinalProject/Semantical_Clustering_Data_Classification_Model/scripts/build_models_text.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                    )\n",
      "File \u001b[1;32mc:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 870, in step_function  **\n        write_scalar_summaries(outputs, step=model._train_counter)  # pylint: disable=protected-access\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 3051, in write_scalar_summaries\n        tf.summary.scalar('batch_' + name, value, step=step)\n    File \"c:\\Users\\natal\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\scalar\\summary_v2.py\", line 84, in scalar\n        getattr(tf.summary.experimental, \"summary_scope\", None)\n\n    AttributeError: module 'tensorboard.summary._tf.summary' has no attribute 'experimental'\n"
     ]
    }
   ],
   "source": [
    "# evalute the model\n",
    "test_loss, test_acc = model.evaluate(test_padseq, Y_test, verbose=0)\n",
    "print(\"test loss and accuracy:\", test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b31755cbf75356c393a3522367cd288f0b05170e2bd292c75b11fc3d2da2cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
